{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:50:54.079233Z",
     "start_time": "2025-05-23T14:50:54.052292Z"
    }
   },
   "source": [
    "def run_pandas():\n",
    "    \"\"\"Implementação completa com Pandas\"\"\"\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.impute import KNNImputer\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # Parte 1: Modelo de ML (ML_Pisa) completa os valores omissos do dataset pisa_2006-2018\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    pisa = pd.read_csv(\"pisa_2006-2018.csv\")\n",
    "    pisa.replace('NA', np.nan, inplace=True)\n",
    "    pisa['Score'] = pd.to_numeric(pisa['Score'], errors='coerce')\n",
    "\n",
    "    # Codificação\n",
    "    le = LabelEncoder()\n",
    "    pisa['Country_encoded'] = le.fit_transform(pisa['Country'])\n",
    "    pisa['Subject_encoded'] = le.fit_transform(pisa['Subject'])\n",
    "\n",
    "    # Modelo\n",
    "    train = pisa.dropna(subset=['Score'])\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(train[['Year', 'Subject_encoded', 'Country_encoded']], train['Score'])\n",
    "\n",
    "    # Previsão\n",
    "    missing = pisa[pisa['Score'].isna()]\n",
    "    if not missing.empty:\n",
    "        pred = model.predict(missing[['Year', 'Subject_encoded', 'Country_encoded']])\n",
    "        pisa.loc[pisa['Score'].isna(), 'Score'] = np.round(pred)\n",
    "\n",
    "    pisa.to_csv(\"pisa_imputed_pandas.csv\", index=False)\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # Parte 2: Junção dos datasets\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Carregar os datasets\n",
    "    pisa_imputed = pd.read_csv(\"pisa_imputed_pandas.csv\")\n",
    "    gdp = pd.read_csv(\"GDP.csv\")\n",
    "\n",
    "    # Corrigir possíveis espaços nos nomes das colunas\n",
    "    gdp.columns = gdp.columns.str.strip()\n",
    "\n",
    "    # Filtrar apenas os anos de interesse no dataset PISA\n",
    "    pisa_imputed = pisa_imputed[pisa_imputed['Year'].isin([2012, 2015, 2018])]\n",
    "\n",
    "    # Filtrar colunas relevantes do GDP\n",
    "    gdp = gdp[['Country', 'Country Code', '2012', '2015', '2018']]\n",
    "\n",
    "    # Obter lista de países comuns\n",
    "    paises_comuns = set(pisa_imputed['Country']).intersection(set(gdp['Country']))\n",
    "\n",
    "    # Filtrar os datasets para manter apenas países comuns\n",
    "    gdp_filtrado = gdp[gdp['Country'].isin(paises_comuns)].copy()\n",
    "    pisa_filtrado = pisa_imputed[pisa_imputed['Country'].isin(paises_comuns)].copy()\n",
    "\n",
    "    # Transformar GDP de wide para long\n",
    "    gdp_long = gdp_filtrado.melt(\n",
    "        id_vars=['Country', 'Country Code'],\n",
    "        value_vars=['2012', '2015', '2018'],\n",
    "        var_name='Year',\n",
    "        value_name='GDP'\n",
    "    )\n",
    "\n",
    "    # Garantir que o ano está como inteiro\n",
    "    gdp_long['Year'] = gdp_long['Year'].astype(int)\n",
    "\n",
    "    # Transformar PISA de long para wide (Subject → colunas)\n",
    "    pisa_wide = pisa_filtrado[['Country', 'Year', 'Subject', 'Score']].pivot_table(\n",
    "        index=['Country', 'Year'],\n",
    "        columns='Subject',\n",
    "        values='Score'\n",
    "    ).reset_index()\n",
    "\n",
    "    # Juntar os datasets\n",
    "    dados_combinados = pd.merge(gdp_long, pisa_wide, on=['Country', 'Year'], how='left')\n",
    "\n",
    "    # Reestruturar para wide por ano\n",
    "    pisa_e_GDP = dados_combinados.pivot(\n",
    "        index=['Country', 'Country Code'],\n",
    "        columns='Year',\n",
    "        values=['GDP', 'Maths', 'Science', 'Reading']\n",
    "    )\n",
    "\n",
    "    # Ajustar nomes das colunas para formato mais legível\n",
    "    pisa_e_GDP.columns = [f\"{var}_{year}\" for var, year in pisa_e_GDP.columns]\n",
    "    pisa_e_GDP = pisa_e_GDP.reset_index()\n",
    "    pisa_e_GDP = pisa_e_GDP.rename(columns={\n",
    "        'Country Code': 'Country_code'\n",
    "    })\n",
    "\n",
    "    pisa_e_GDP.to_csv(\"pisa_e_GDP.csv\", index=False)\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # Parte 3: Processamento do GDP_PISA (ML_GDP_Pisa)\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    dt = pd.read_csv(\"pisa_e_GDP.csv\")\n",
    "\n",
    "    # Tratamento de NAs\n",
    "    print(\"\\n[Pandas] Valores NaN antes:\", dt.isna().sum().sum())\n",
    "\n",
    "    # Salvar máscara de valores ausentes para usar depois\n",
    "    missing_mask = dt.isna()\n",
    "\n",
    "    colunas_numericas = dt.select_dtypes(include=[np.number]).columns\n",
    "    scaler = StandardScaler()\n",
    "    dt_scaled = dt.copy()\n",
    "    dt_scaled[colunas_numericas] = scaler.fit_transform(dt[colunas_numericas])\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    dt_imputed_scaled = dt_scaled.copy()\n",
    "    dt_imputed_scaled[colunas_numericas] = imputer.fit_transform(dt_scaled[colunas_numericas])\n",
    "\n",
    "    dt_imputed = dt.copy()\n",
    "    dt_imputed[colunas_numericas] = scaler.inverse_transform(dt_imputed_scaled[colunas_numericas])\n",
    "\n",
    "    # Formatação\n",
    "    colunas_gdp = [\"GDP_2012\", \"GDP_2015\", \"GDP_2018\"]\n",
    "    dt_imputed[colunas_gdp] = dt_imputed[colunas_gdp].round(5)\n",
    "\n",
    "    # Correção: Aplicar arredondamento e conversão para int apenas nas células que eram NaN\n",
    "    # Exclui colunas GDP que já foram tratadas separadamente\n",
    "    colunas_para_arredondar = [col for col in colunas_numericas if col not in colunas_gdp]\n",
    "\n",
    "    for col in colunas_para_arredondar:\n",
    "        if missing_mask[col].any():\n",
    "            dt_imputed.loc[missing_mask[col], col] = dt_imputed.loc[missing_mask[col], col].round(0).astype(int)\n",
    "\n",
    "    print(\"[Pandas] Valores NaN após:\", dt_imputed.isna().sum().sum())\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # Parte 4: Adicionar as médias dos anos e das disciplinas\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Criar novas colunas com médias das disciplinas arredondadas a 3 casas decimais\n",
    "    dt_imputed['Means_Maths'] = dt_imputed[['Maths_2012', 'Maths_2015', 'Maths_2018']].mean(axis=1, skipna=True).round(3)\n",
    "    dt_imputed['Means_Science'] = dt_imputed[['Science_2012', 'Science_2015', 'Science_2018']].mean(axis=1, skipna=True).round(3)\n",
    "    dt_imputed['Means_Reading'] = dt_imputed[['Reading_2012', 'Reading_2015', 'Reading_2018']].mean(axis=1, skipna=True).round(3)\n",
    "\n",
    "    dt_imputed['Mean_2012'] = dt_imputed[[c for c in dt_imputed.columns if '2012' in c and 'GDP' not in c]].mean(axis=1).round(3)\n",
    "    dt_imputed['Mean_2015'] = dt_imputed[[c for c in dt_imputed.columns if '2015' in c and 'GDP' not in c]].mean(axis=1).round(3)\n",
    "    dt_imputed['Mean_2018'] = dt_imputed[[c for c in dt_imputed.columns if '2018' in c and 'GDP' not in c]].mean(axis=1).round(3)\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # Parte 5: Adicionar variações relativas (%) entre anos\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Variação percentual do GDP\n",
    "    dt_imputed['GDP_change_2012_2015'] = ((dt_imputed['GDP_2015'] - dt_imputed['GDP_2012']) / dt_imputed['GDP_2012'] * 100).round(2)\n",
    "    dt_imputed['GDP_change_2015_2018'] = ((dt_imputed['GDP_2018'] - dt_imputed['GDP_2015']) / dt_imputed['GDP_2015'] * 100).round(2)\n",
    "\n",
    "    # Variação percentual das médias PISA\n",
    "    dt_imputed['PISA_change_2012_2015'] = ((dt_imputed['Mean_2015'] - dt_imputed['Mean_2012']) / dt_imputed['Mean_2012'] * 100).round(2)\n",
    "    dt_imputed['PISA_change_2015_2018'] = ((dt_imputed['Mean_2018'] - dt_imputed['Mean_2015']) / dt_imputed['Mean_2015'] * 100).round(2)\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # Parte 6: Rácio GDP / PISA Score por ano\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    dt_imputed['GDP_per_PISA_2012'] = (dt_imputed['GDP_2012'] / dt_imputed['Mean_2012']).round(4)\n",
    "    dt_imputed['GDP_per_PISA_2015'] = (dt_imputed['GDP_2015'] / dt_imputed['Mean_2015']).round(4)\n",
    "    dt_imputed['GDP_per_PISA_2018'] = (dt_imputed['GDP_2018'] / dt_imputed['Mean_2018']).round(4)\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # Parte 7: Diferença absoluta das pontuações PISA e do GDP entre anos\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Diferença absoluta\n",
    "    dt_imputed['GDP_diff_2012_2015'] = (dt_imputed['GDP_2015'] - dt_imputed['GDP_2012']).round(3)\n",
    "    dt_imputed['GDP_diff_2015_2018'] = (dt_imputed['GDP_2018'] - dt_imputed['GDP_2015']).round(3)\n",
    "\n",
    "    dt_imputed['PISA_diff_2012_2015'] = (dt_imputed['Mean_2015'] - dt_imputed['Mean_2012']).round(3)\n",
    "    dt_imputed['PISA_diff_2015_2018'] = (dt_imputed['Mean_2018'] - dt_imputed['Mean_2015']).round(3)\n",
    "\n",
    "    dt_imputed.to_excel(\"Dataset_final_pandas.xlsx\", index=False)\n",
    "\n",
    "    return \" Resultados gravados em 'Dataset_final_pandas.xlsx' \""
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T14:50:56.441001Z",
     "start_time": "2025-05-23T14:50:56.103306Z"
    }
   },
   "cell_type": "code",
   "source": "run_pandas()",
   "id": "31346f93833cdbb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pandas] Valores NaN antes: 70\n",
      "[Pandas] Valores NaN após: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Resultados gravados em 'Dataset_final_pandas.xlsx' \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
